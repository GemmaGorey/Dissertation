{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf8BtX0bw/MjQTkexfJU5a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GemmaGorey/Dissertation/blob/main/Dissertation_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB327CIPG0v4"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "# install mamba to use instead of pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the config file and build the environment.\n",
        "yaml_content = \"\"\"\n",
        "name: dissertation\n",
        "channels:\n",
        "  - pytorch\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.11\n",
        "  - pytorch=2.2.2\n",
        "  - torchvision=0.17.2\n",
        "  - torchaudio\n",
        "  - librosa\n",
        "  - numpy<2\n",
        "  - pandas\n",
        "  - jupyter\n",
        "  - wandb\n",
        "\"\"\"\n",
        "\n",
        "# Write the string content to a file -  'environment.yml'.\n",
        "with open('environment.yml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"environment.yml file created successfully.\")\n",
        "\n",
        "# create the environment using mamba from the yml file.\n",
        "print(\"\\n Creating environment\")\n",
        "\n",
        "!mamba env create -f environment.yml --quiet && echo -e \"\\n 'dissertation' environment is ready to use.\""
      ],
      "metadata": {
        "id": "NqkjmK3RHcYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports and setting up of GitHub and W&B\n",
        "\n",
        "# clone project repository from GitHub\n",
        "print(\"⏳ Cloning GitHub repository...\")\n",
        "!git clone https://github.com/GemmaGorey/Dissertation.git\n",
        "print(\"Repository cloned.\")\n",
        "\n",
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#imports\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') #loading the tokenizer for lyrics processing\n",
        "print(\"Tokenizer loaded.\")"
      ],
      "metadata": {
        "id": "tG0a7AkQHf2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data from the saved file\n",
        "#path to where this was saved\n",
        "base_path = '/content/drive/MyDrive/dissertation/output_from_code/'\n",
        "master_file_path = os.path.join(base_path, 'master_processed_file_list.csv')\n",
        "\n",
        "#load the master csv with all the paths and VA values\n",
        "master_df = pd.read_csv(master_file_path)\n",
        "\n",
        "print(\"Master csv loaded\")\n",
        "display(master_df.head())\n",
        "\n",
        "#check data for 1 song\n",
        "#pick a song between 0 and 2215\n",
        "test_final_song_index = 1111\n",
        "song_info = master_df.iloc[test_final_song_index]\n",
        "\n",
        "print(f\"\\n--- Loading data for song: {song_info['song_id']} ---\")\n",
        "\n",
        "#Load the spectrogram from the file\n",
        "spectrogram = np.load(song_info['spectrogram_path'])\n",
        "\n",
        "#load the lyric tensors\n",
        "encoded_lyrics = torch.load(song_info['lyrics_path'], weights_only=False)\n",
        "\n",
        "#Get the labels\n",
        "valence = song_info['valence']\n",
        "arousal = song_info['arousal']\n",
        "\n",
        "#check the data\n",
        "print(\"Spectrogram Shape:\", spectrogram.shape)\n",
        "print(\"Encoded Lyrics Tensors:\", encoded_lyrics)\n",
        "print(f\"Labels - Valence: {valence}, Arousal: {arousal}\")\n"
      ],
      "metadata": {
        "id": "KUbPRcEUHrTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To-Do:\n",
        "Create a custom PyTorch Dataset to load items from master_df.\n",
        "\n",
        "Wrap the Dataset in a DataLoader.\n",
        "\n",
        "Start building the model architecture (CNN for audio, Transformer for text)."
      ],
      "metadata": {
        "id": "793Ry0mKJdSB"
      }
    }
  ]
}