{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrrhHtu+IHr4jGYA7QmnAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GemmaGorey/Dissertation/blob/main/Dissertation_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB327CIPG0v4"
      },
      "outputs": [],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "# install mamba to use instead of pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the config file and build the environment.\n",
        "yaml_content = \"\"\"\n",
        "name: dissertation\n",
        "channels:\n",
        "  - pytorch\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.11\n",
        "  - pytorch=2.2.2\n",
        "  - torchvision=0.17.2\n",
        "  - torchaudio\n",
        "  - librosa\n",
        "  - numpy<2\n",
        "  - pandas\n",
        "  - jupyter\n",
        "  - wandb\n",
        "\"\"\"\n",
        "\n",
        "# Write the string content to a file -  'environment.yml'.\n",
        "with open('environment.yml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"environment.yml file created successfully.\")\n",
        "\n",
        "# create the environment using mamba from the yml file.\n",
        "print(\"\\n Creating environment\")\n",
        "\n",
        "!mamba env create -f environment.yml --quiet && echo -e \"\\n 'dissertation' environment is ready to use.\""
      ],
      "metadata": {
        "id": "NqkjmK3RHcYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports and setting up of GitHub and W&B\n",
        "\n",
        "# clone project repository from GitHub\n",
        "print(\"â³ Cloning GitHub repository...\")\n",
        "!git clone https://github.com/GemmaGorey/Dissertation.git\n",
        "print(\"Repository cloned.\")\n",
        "\n",
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#imports\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased') #loading the tokenizer for lyrics processing\n",
        "print(\"Tokenizer loaded.\")"
      ],
      "metadata": {
        "id": "tG0a7AkQHf2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data from the saved file\n",
        "#path to where this was saved\n",
        "base_path = '/content/drive/MyDrive/dissertation/output_from_code/'\n",
        "master_file_path = os.path.join(base_path, 'master_processed_file_list.csv')\n",
        "\n",
        "#load the master csv with all the paths and VA values\n",
        "master_df = pd.read_csv(master_file_path)\n",
        "\n",
        "print(\"Master csv loaded\")\n",
        "display(master_df.head())\n",
        "\n",
        "#check data for 1 song\n",
        "#pick a song between 0 and 2215\n",
        "test_final_song_index = 9\n",
        "song_info = master_df.iloc[test_final_song_index]\n",
        "\n",
        "print(f\"\\n--- Loading data for song: {song_info['song_id']} ---\")\n",
        "\n",
        "#Load the spectrogram from the file\n",
        "spectrogram = np.load(song_info['spectrogram_path'])\n",
        "\n",
        "#load the lyric tensors\n",
        "encoded_lyrics = torch.load(song_info['lyrics_path'], weights_only=False)\n",
        "\n",
        "#Get the labels\n",
        "valence = song_info['valence']\n",
        "arousal = song_info['arousal']\n",
        "\n",
        "#check the data\n",
        "print(\"Spectrogram Shape:\", spectrogram.shape)\n",
        "print(\"Encoded Lyrics Tensors:\", encoded_lyrics)\n",
        "print(f\"Labels - Valence: {valence}, Arousal: {arousal}\")\n"
      ],
      "metadata": {
        "id": "KUbPRcEUHrTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MER_Dataset(Dataset):\n",
        "    \"\"\" Custom PyTorch Dataset for loading MER data. \"\"\"\n",
        "    def __init__(self, annotations_df, tokenizer):\n",
        "        \"\"\" Creation of the Dataset from the dataframe (predefined splits in MERGE dataset) \"\"\"\n",
        "        self.annotations = annotations_df\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Function to return the total number of songs in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Function to get a song from the dataset.\n",
        "        \"\"\"\n",
        "        song_info = self.annotations.iloc[index] #which song ID/row is picked from the dataset as per the index\n",
        "\n",
        "        spectrogram_path = song_info['spectrogram_path'] # columns from the df\n",
        "        lyrics_path = song_info['lyrics_path'] # columns from the df\n",
        "        valence = song_info['valence'] # columns from the df\n",
        "        arousal = song_info['arousal'] # columns from the df\n",
        "\n",
        "        #change spectorgram into a tensor\n",
        "        spectrogram = np.load(spectrogram_path) #loading spectorgram from path saved in df\n",
        "        spectrogram_tensor = torch.from_numpy(spectrogram).float() # changing the np array to tensor\n",
        "        spectrogram_tensor = spectrogram_tensor.unsqueeze(0) #Adding a \"channel\" dimension for CNN\n",
        "\n",
        "        #Load the lyric tokens\n",
        "        encoded_lyrics = torch.load(lyrics_path, weights_only=False)\n",
        "        input_ids = encoded_lyrics['input_ids'].squeeze(0) #remove the batch dimension from input ids so 1d\n",
        "        attention_mask = encoded_lyrics['attention_mask'].squeeze(0) #remove the batch dimension from attention mask so 1d\n",
        "\n",
        "\n",
        "        labels = torch.tensor([valence, arousal], dtype=torch.float32) # extract labels\n",
        "\n",
        "\n",
        "        return spectrogram_tensor, input_ids, attention_mask, labels"
      ],
      "metadata": {
        "id": "RWoc_3CmRvx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the csv for where the predefined splits are located in Google drive\n",
        "split_folder_path = '/content/drive/MyDrive/dissertation/MERGE_Bimodal_Complete/tvt_dataframes/tvt_70_15_15/'\n",
        "\n",
        "#read the files and load into variables\n",
        "train_split_df = pd.read_csv(os.path.join(split_folder_path, 'tvt_70_15_15_train_bimodal_complete.csv'))\n",
        "val_split_df = pd.read_csv(os.path.join(split_folder_path, 'tvt_70_15_15_validate_bimodal_complete.csv'))\n",
        "test_split_df = pd.read_csv(os.path.join(split_folder_path, 'tvt_70_15_15_test_bimodal_complete.csv'))\n",
        "\n",
        "id_column_name = 'song_id' #match the naming in the master data and replace in test/train/split\n",
        "train_split_df.rename(columns={'Song': id_column_name}, inplace=True)\n",
        "val_split_df.rename(columns={'Song': id_column_name}, inplace=True)\n",
        "test_split_df.rename(columns={'Song': id_column_name}, inplace=True)\n",
        "\n",
        "#filter the master dataset to create the three smaller datasets\n",
        "train_df = pd.merge(master_df, train_split_df, on=id_column_name)\n",
        "val_df = pd.merge(master_df, val_split_df, on=id_column_name)\n",
        "test_df = pd.merge(master_df, test_split_df, on=id_column_name)\n",
        "\n",
        "print(f\"Total training samples: {len(train_df)}\") # check these against the csv train should have 1552 songs\n",
        "print(f\"Total validation samples: {len(val_df)}\") # check these against the csv train should have 332 songs\n",
        "print(f\"Total test samples: {len(test_df)}\") # check these against the csv train should have 332 songs\n",
        "\n",
        "# Create separate dataloaders and datasets.\n",
        "train_dataset = MER_Dataset(annotations_df=train_df, tokenizer=tokenizer)\n",
        "val_dataset = MER_Dataset(annotations_df=val_df, tokenizer=tokenizer)\n",
        "test_dataset = MER_Dataset(annotations_df=test_df, tokenizer=tokenizer)\n",
        "\n",
        "BATCH_SIZE = 16 #using for now, but can change this in the future\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True) #shuffle training dataset but not others.\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "#verify a batch\n",
        "spectrogram_batch, input_ids_batch, attention_mask_batch, labels_batch = next(iter(train_loader))\n",
        "\n",
        "print(\"\\Verifying a batch from the new train_loader ---\")\n",
        "print(f\"Spectrogram batch shape: {spectrogram_batch.shape}\")\n",
        "print(f\"Input IDs batch shape: {input_ids_batch.shape}\")\n",
        "print(f\"Labels batch shape: {labels_batch.shape}\")"
      ],
      "metadata": {
        "id": "4F5-XOUmY2VC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}